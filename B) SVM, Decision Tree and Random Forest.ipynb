{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>slope_of_peak_exercise_st_segment</th>\n",
       "      <th>thal</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>num_major_vessels</th>\n",
       "      <th>fasting_blood_sugar_gt_120_mg_per_dl</th>\n",
       "      <th>resting_ekg_results</th>\n",
       "      <th>serum_cholesterol_mg_per_dl</th>\n",
       "      <th>oldpeak_eq_st_depression</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "      <th>heart_disease_present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0z64un</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ryoo3j</td>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yt1s1x</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2xjde</td>\n",
       "      <td>1</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oyt4ek</td>\n",
       "      <td>3</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>270</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id  slope_of_peak_exercise_st_segment               thal  \\\n",
       "0     0z64un                                  1             normal   \n",
       "1     ryoo3j                                  2             normal   \n",
       "2     yt1s1x                                  1             normal   \n",
       "3     l2xjde                                  1  reversible_defect   \n",
       "4     oyt4ek                                  3  reversible_defect   \n",
       "\n",
       "   resting_blood_pressure  chest_pain_type  num_major_vessels  \\\n",
       "0                     128                2                  0   \n",
       "1                     110                3                  0   \n",
       "2                     125                4                  3   \n",
       "3                     152                4                  0   \n",
       "4                     178                1                  0   \n",
       "\n",
       "   fasting_blood_sugar_gt_120_mg_per_dl  resting_ekg_results  \\\n",
       "0                                     0                    2   \n",
       "1                                     0                    0   \n",
       "2                                     0                    2   \n",
       "3                                     0                    0   \n",
       "4                                     0                    2   \n",
       "\n",
       "   serum_cholesterol_mg_per_dl  oldpeak_eq_st_depression  sex  age  \\\n",
       "0                          308                       0.0    1   45   \n",
       "1                          214                       1.6    0   54   \n",
       "2                          304                       0.0    1   77   \n",
       "3                          223                       0.0    1   40   \n",
       "4                          270                       4.2    1   59   \n",
       "\n",
       "   max_heart_rate_achieved  exercise_induced_angina  heart_disease_present  \n",
       "0                      170                        0                      0  \n",
       "1                      158                        0                      0  \n",
       "2                      162                        1                      1  \n",
       "3                      181                        0                      1  \n",
       "4                      145                        0                      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df = heart_df=pd.read_csv(\"C:\\\\Users\\\\Ankita & Subhash\\\\Desktop\\\\MSITM\\\\Fall Semester 2018\\\\Machine Learning\\\\Project\\\\Data From Competition Website\\\\train_values.csv\")\n",
    "heart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This above line of executed code indicates that there are 180 rows and 15 columns within the above dataset. In the next step let's divide the data into attributes and labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heart_df.drop(['patient_id', 'thal'], axis=1, inplace=True)\n",
    "heart_df.head()\n",
    "\n",
    "X = heart_df.drop('heart_disease_present', axis=1)  \n",
    "y = heart_df['heart_disease_present'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code lines, X contains the attributes of the data frame and y contains the labels that we are willing to predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Splitting\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=8, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Algorithm\n",
    "from sklearn.svm import SVC  \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "svclassifier = SVC(kernel='linear', degree=8)  \n",
    "svclassifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making Predictions\n",
    "y_pred = svclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20  3]\n",
      " [ 1 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.87      0.91        23\n",
      "           1       0.80      0.92      0.86        13\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        36\n",
      "   macro avg       0.88      0.90      0.88        36\n",
      "weighted avg       0.90      0.89      0.89        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Algorithm Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As compared to our previous Logistic Regression, this time using linear kernel helped in improving the model's performance to a high value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankita & Subhash\\AppData\\Local\\conda\\conda\\envs\\analysis\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.655 (+/-0.125) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.611 (+/-0.072) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.551 (+/-0.114) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.665 (+/-0.086) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.574 (+/-0.111) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.699 (+/-0.139) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.603 (+/-0.094) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.731 (+/-0.069) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.803 (+/-0.053) for {'C': 1, 'kernel': 'linear'}\n",
      "0.777 (+/-0.101) for {'C': 10, 'kernel': 'linear'}\n",
      "0.779 (+/-0.116) for {'C': 100, 'kernel': 'linear'}\n",
      "0.743 (+/-0.161) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84        18\n",
      "           1       0.88      0.78      0.82        18\n",
      "\n",
      "   micro avg       0.83      0.83      0.83        36\n",
      "   macro avg       0.84      0.83      0.83        36\n",
      "weighted avg       0.84      0.83      0.83        36\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankita & Subhash\\AppData\\Local\\conda\\conda\\envs\\analysis\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.640 (+/-0.114) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.588 (+/-0.058) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.551 (+/-0.115) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.642 (+/-0.081) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.575 (+/-0.110) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.687 (+/-0.143) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.604 (+/-0.096) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.721 (+/-0.076) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.782 (+/-0.042) for {'C': 1, 'kernel': 'linear'}\n",
      "0.746 (+/-0.082) for {'C': 10, 'kernel': 'linear'}\n",
      "0.762 (+/-0.082) for {'C': 100, 'kernel': 'linear'}\n",
      "0.733 (+/-0.154) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84        18\n",
      "           1       0.88      0.78      0.82        18\n",
      "\n",
      "   micro avg       0.83      0.83      0.83        36\n",
      "   macro avg       0.84      0.83      0.83        36\n",
      "weighted avg       0.84      0.83      0.83        36\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the parameters by cross-validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from __future__ import print_function\n",
    "print(__doc__)\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5,   #5 fold cross-validation\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Polynomial Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=8, gamma='auto_deprecated',\n",
       "  kernel='poly', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC  \n",
    "svclassifier = SVC(kernel='poly', degree=8)  \n",
    "svclassifier.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making Predictions\n",
    "y_pred = svclassifier.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13 10]\n",
      " [ 2 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.57      0.68        23\n",
      "           1       0.52      0.85      0.65        13\n",
      "\n",
      "   micro avg       0.67      0.67      0.67        36\n",
      "   macro avg       0.70      0.71      0.67        36\n",
      "weighted avg       0.74      0.67      0.67        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Algorithm Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time our Model's performance seems to have detoriated than the previous Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC  \n",
    "svclassifier = SVC(kernel='rbf')  \n",
    "svclassifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction and Evaluation\n",
    "y_pred = svclassifier.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23  0]\n",
      " [13  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      1.00      0.78        23\n",
      "           1       0.00      0.00      0.00        13\n",
      "\n",
      "   micro avg       0.64      0.64      0.64        36\n",
      "   macro avg       0.32      0.50      0.39        36\n",
      "weighted avg       0.41      0.64      0.50        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankita & Subhash\\AppData\\Local\\conda\\conda\\envs\\analysis\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Algorithm Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay this time, the Model's performance seemed to have detoriated much more than the previous Model. So, far Simple SVM seems to perform the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sigmoid Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='sigmoid', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC  \n",
    "svclassifier = SVC(kernel='sigmoid')  \n",
    "svclassifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction and Evaluation\n",
    "y_pred = svclassifier.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23  0]\n",
      " [13  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      1.00      0.78        23\n",
      "           1       0.00      0.00      0.00        13\n",
      "\n",
      "   micro avg       0.64      0.64      0.64        36\n",
      "   macro avg       0.32      0.50      0.39        36\n",
      "weighted avg       0.41      0.64      0.50        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankita & Subhash\\AppData\\Local\\conda\\conda\\envs\\analysis\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Algorithm Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, running all the Models, our Simple SVM Model still semms to ein over all other SVM Models and it even performs better than our previous Models ran on the basis of Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "classifier = DecisionTreeClassifier()  \n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction and Evaluation\n",
    "y_pred = classifier.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17  6]\n",
      " [ 4  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.77        23\n",
      "           1       0.60      0.69      0.64        13\n",
      "\n",
      "   micro avg       0.72      0.72      0.72        36\n",
      "   macro avg       0.70      0.72      0.71        36\n",
      "weighted avg       0.73      0.72      0.73        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Algorithm Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Model performed however better than the previous Models, except for Simple SVM Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  4]\n",
      " [ 2 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86        23\n",
      "           1       0.73      0.85      0.79        13\n",
      "\n",
      "   micro avg       0.83      0.83      0.83        36\n",
      "   macro avg       0.82      0.84      0.82        36\n",
      "weighted avg       0.84      0.83      0.84        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Model, the Model Accuracy and Model F1 Score seems to be close and therefore we can conclude a better performance in terms of Model's predictive power."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
